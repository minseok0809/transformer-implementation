{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development Envrionment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tqdm\n",
    "import glob\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huggingface Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 206112\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 888\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 8079\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('iwslt2017')\n",
    "dataset\n",
    "for split, split_dataset in dataset.items():\n",
    "    split_dataset.to_json(f\"data/iwslt17.de.en.huggingface/{split}-de-en.json\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': {'de': 'Vielen Dank, Chris.',\n",
       "  'en': 'Thank you so much, Chris.'}}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TGZ to TXT & XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[IWSLT 2017-01](https://wit3.fbk.eu/2017-01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf ./data/iwslt17.de.en.orig/tgz/2017-01-trnmted.tgz -C ./data/iwslt17.de.en.orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf ./data/iwslt17.de.en.orig/2017-01-trnmted/texts/DeEnItNlRo/DeEnItNlRo/DeEnItNlRo-DeEnItNlRo.tgz -C ./data/iwslt17.de.en.orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./data/iwslt17.de.en.orig/DeEnItNlRo-DeEnItNlRo/train.tags.de-en.de ./data/iwslt17.de.en.orig/xml/train/train.tags.de-en.de.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./data/iwslt17.de.en.orig/DeEnItNlRo-DeEnItNlRo/train.tags.de-en.en ./data/iwslt17.de.en.orig/xml/train/train.tags.de-en.en.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -lir 'dev2010' ./data/iwslt17.de.en.orig/DeEnItNlRo-DeEnItNlRo/* | xargs mv -t ./data/iwslt17.de.en.orig/xml/dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[IWSLT 2017-01-B](https://wit3.fbk.eu/2017-01-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf ./data/iwslt17.de.en.orig/tgz/2017-01-mted-test.tgz -C ./data/iwslt17.de.en.orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf ./data/iwslt17.de.en.orig/2017-01-mted-test/texts/de/en/de-en.tgz -C ./data/iwslt17.de.en.orig/xml/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf ./data/iwslt17.de.en.orig/2017-01-mted-test/texts/en/de/en-de.tgz -C ./data/iwslt17.de.en.orig/xml/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ./data/iwslt17.de.en.orig/xml/test/de-en/IWSLT17.TED.tst2017.mltlng.de-en.de.xml ./data/iwslt17.de.en.orig/xml/test/IWSLT17.TED.tst2017.mltlng.de-en.de.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ./data/iwslt17.de.en.orig/xml/test/en-de/IWSLT17.TED.tst2017.mltlng.en-de.en.xml ./data/iwslt17.de.en.orig/xml/test/IWSLT17.TED.tst2017.mltlng.en-de.en.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ./data/iwslt17.de.en.orig/xml/test/de-en\n",
    "!rm -r ./data/iwslt17.de.en.orig/xml/test/en-de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TXT to XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt_paths = glob.glob(\"./data/iwslt17.de.en.orig/xml/**/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_source_file_list(l, n): \n",
    "    \n",
    "  for i in range(0, len(l), n): \n",
    "    yield l[i:i + n] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223164/223164 [00:24<00:00, 9272.51it/s] \n",
      "100%|██████████| 223163/223163 [00:23<00:00, 9353.23it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    xml_path = path.replace(\"txt\", \"xml\")\\n    with open(xml_path, \\'w+\\') as f:\\n        text = text.split(\"\\n\")\\n        for line in text:\\n            f.write(line + \"\\n\")\\n'"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for path in train_txt_paths:\n",
    "\n",
    "    xml_text = ET.Element('xml')\n",
    "    xml_text.set('version', 'Accepted')\n",
    "    xml_text.set('encoding', 'UTF-8')\n",
    "\n",
    "    num = 0; num_list = []\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.read().splitlines() \n",
    "        for line in lines:\n",
    "            num += 1\n",
    "            if '</description>' in line:\n",
    "                num_list.append(num)\n",
    "            elif '</reviewer>' in line:\n",
    "                num_list.append(num)\n",
    "\n",
    "    num_list = list(divide_source_file_list(num_list, 2))\n",
    "\n",
    "    text = \"\"; num = 0; del_num = 0\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.read().splitlines() \n",
    "        with tqdm.tqdm(lines) as pbar:\n",
    "            for line in pbar:\n",
    "                num += 1\n",
    "                for idx, value in enumerate(num_list):\n",
    "                    if num > value[0] and num < value[1]:\n",
    "                        seg_num += 1\n",
    "                        seg_name = \"seg\" + str(seg_num)\n",
    "                        globals()[seg_name] = ET.SubElement(xml_text, \"seg\")\n",
    "                        globals()[seg_name].set('type', str(seg_num))\n",
    "                        globals()[seg_name].text = line\n",
    "                    if num == value[1]:\n",
    "                        del num_list[idx - del_num]\n",
    "                        del_num += 1\n",
    "                        seg_num = 0\n",
    "        pbar.close()\n",
    "\n",
    "    xml_text = ET.tostring(xml_text)\n",
    "    xml_path = path.replace(\"txt\", \"xml\")\n",
    "    with open(xml_path, \"wb\") as f:\n",
    "        f.write(xml_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xml_paths = []; dev_xml_paths = []; test_xml_paths = []\n",
    "\n",
    "xml_paths = glob.glob(\"./data/iwslt17.de.en.orig/xml/**/*.xml\")\n",
    "\n",
    "for i in xml_paths:\n",
    "    if all(j in i for j in ['train', 'de-en']):\n",
    "        train_xml_paths.append(i)\n",
    "    elif all(j in i for j in ['dev', 'de-en']):\n",
    "        dev_xml_paths.append(i)\n",
    "    elif all(j in i for j in ['test']):\n",
    "        test_xml_paths.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(train_xml_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: \n",
      "['seg', 'xml']\n",
      "\n",
      "Validation & Evaluation Data: \n",
      "['doc', 'title', 'translator', 'reviewer', 'mteval', 'talkid', 'seg', 'description', 'url', 'keywords', 'refset']\n"
     ]
    }
   ],
   "source": [
    "temp_paths = [train_xml_paths[0], dev_xml_paths[0], test_xml_paths[0]]\n",
    "\n",
    "for path in temp_paths :\n",
    "    tree = ET.parse(path)\n",
    "\n",
    "    root = tree.getroot()\n",
    "    # ET.dump(tree)\n",
    "\n",
    "    elemList = [elem.tag for elem in tree.iter()]\n",
    "    elemList = list(set(elemList))\n",
    "    if 'train' in path: print(\"Train Data: \"); print(str(elemList) + \"\\n\")\n",
    "    elif 'dev' in path: print(\"Validation & Evaluation Data: \"); print(elemList) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_json(xml_paths):\n",
    "    de_texts = []; en_texts = []\n",
    "    for path in xml_paths:\n",
    "        tree = ET.parse(path)\n",
    "        for seg in tree.iter('seg'):\n",
    "            sample_text = seg.text\n",
    "            \n",
    "        if 'sample_text' in locals():\n",
    "            del sample_text\n",
    "            for seg in tree.iter('seg'):\n",
    "                text = seg.text.strip()\n",
    "                \n",
    "                if path.split('.')[-2] == 'de':  de_texts.append(text)\n",
    "                elif path.split('.')[-2] == 'en': en_texts.append(text)\n",
    "                \n",
    "        else:\n",
    "            for refset in tree.iter('refset'):\n",
    "                for seg in refset.iter('seg'):\n",
    "                    text = seg.text.strip()\n",
    "                    if path.split('.')[-2] == 'de':  de_texts.append(text)\n",
    "                    elif path.split('.')[-2] == 'en': en_texts.append(text)\n",
    "    \n",
    "    texts = []\n",
    "    for de, en in zip(de_texts, en_texts):\n",
    "        pair_dict = {}; pair_dict[\"de\"] = de; pair_dict[\"en\"] = en\n",
    "        trans_dict = {}; trans_dict[\"translation\"] = pair_dict\n",
    "        texts.append(trans_dict)\n",
    "    \n",
    "    if 'train' in xml_paths[0]: split = 'train'; \n",
    "    elif 'dev' in xml_paths[0]: split = 'validation'\n",
    "    elif 'test' in xml_paths[0]: split = 'test'\n",
    "\n",
    "    save_json_path = './datasets/iwslt17.de.en/' + split + '-de-en.json'\n",
    "\n",
    "    with open(save_json_path, 'w') as fp:\n",
    "        fp.write('[' + ',\\n'.join(json.dumps(i, ensure_ascii=False) for i in texts) + ']\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_paths = [train_xml_paths, dev_xml_paths, test_xml_paths]\n",
    "\n",
    "for xml_path in xml_paths:\n",
    "    xml_to_json(xml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huggingface Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 0 examples [00:00, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 116654 examples [00:00, 259924.33 examples/s]\n",
      "Generating validation split: 888 examples [00:00, 307966.09 examples/s]\n",
      "Generating test split: 1138 examples [00:00, 439918.71 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 116654\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 888\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 1138\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('./data/iwslt17.de.en')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': {'de': 'Vielen Dank, Chris.',\n",
       "  'en': 'Thank you so much, Chris.'}}"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Paper</b>\n",
    "<br>[Attention is all you need](https://arxiv.org/abs/1706.03762)\n",
    "\n",
    "<br><b>Data</b>\n",
    "<br>[IWSLT 2017-01](https://wit3.fbk.eu/2017-01)\n",
    "<br>[IWSLT 2017-01-B](https://wit3.fbk.eu/2017-01-b)\n",
    "\n",
    "<br><b>GeekforGeeks</b>\n",
    "<br>[Reading and Writing XML Files in Python](https://www.geeksforgeeks.org/reading-and-writing-xml-files-in-python/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
