{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tramsformer Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from directory_tree import display_tree\n",
    "customPath = './'\n",
    "directory_tree = display_tree(customPath, max_depth=5, string_rep=True, show_hidden=True)\n",
    "with open(\"debug/transformer_directory_tree.txt\", \"w\") as f:\n",
    "    f.write(directory_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-19 10:14:14.581135: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-19 10:14:15.178869: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=data/iwslt17.de.en/txt/train-de.txt,data/iwslt17.de.en/txt/valid-de.txt,data/iwslt17.de.en/txt/test-de.txt --model_prefix=./data/iwslt17.de.en/tokenizer/transformer-sp-bpe-iwslt-de --vocab_size=37000 --minloglevel=2 --model_type=bpe --vocab_size=37000 --max_sentence_length=999999 --character_coverage=1.0 --pad_id=0 --pad_piece=<pad> --unk_id=1 --unk_piece=<unk> --bos_id=2 --bos_piece=<s> --eos_id=3 --eos_piece=</s>\n",
      "Epoch 1: 100%|████████████████████████████████| 912/912 [00:17<00:00, 51.81it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "!python -m train \\\n",
    "    --mode 'debug' \\\n",
    "    --train_eval_predict 'T_T_T' \\\n",
    "    --model_name 'demo_transformer_base' \\\n",
    "    --config './config/demo_transformer_base.json' \\\n",
    "    --data_dir './data/iwslt17.de.en/' \\\n",
    "    --txt_dir 'txt/' \\\n",
    "    --tokenizer_dir 'data/iwslt17.de.en/tokenizer' \\\n",
    "    --tokenizer_model_name 'transformer-sp-bpe-iwslt' \\\n",
    "    --encoding_type 'bpe' \\\n",
    "    --src_lang 'de' \\\n",
    "    --tgt_lang 'en' \\\n",
    "    --max_seq_length 50 \\\n",
    "    --vocab_size 37000 \\\n",
    "    --pad_id 0 \\\n",
    "    --unk_id 1 \\\n",
    "    --bos_id 2 \\\n",
    "    --eos_id 3 \\\n",
    "    --evaluation_metric 'bleu' \\\n",
    "    --seed 42 \\\n",
    "    --epoch 100 \\\n",
    "    --logging_step 100 \\\n",
    "    --gpu 0 \\\n",
    "    --batch_size 128 \\\n",
    "    --sinusoidal_wave 10000 \\\n",
    "    --embedding_dim 512 \\\n",
    "    --num_attention_heads 8 \\\n",
    "    --num_sub_layer 6 \\\n",
    "    --feed_forward_size 2048 \\\n",
    "    --attention_dropout_prob 0.1 \\\n",
    "    --label_smoothing 0.1 \\\n",
    "    --optimizer_coefficient 0.1 \\\n",
    "    --warmup_steps 4000 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --adam_beta1 0.9 \\\n",
    "    --adam_beta2 0.98 \\\n",
    "    --adam_epsilon 1e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-22 02:55:42.923874: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-22 02:55:43.844498: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=./data/iwslt17.de.en/txt/train-de.txt,./data/iwslt17.de.en/txt/valid-de.txt --model_prefix=data/iwslt17.de.en/tokenizer/transformer-sp-bpe-iwslt-de --vocab_size=18500 --model_type=bpe --bos_id=2 --eos_id=3 --pad_id=0 --unk_id=1 --minloglevel=2\n",
      "  0%|                                                   | 0/912 [00:00<?, ?it/s][INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "100%|█████████████████████████████████████████| 912/912 [01:50<00:00,  8.24it/s]\n",
      "\n",
      "\n",
      "Parameters:14775428.0 \n",
      "\n",
      "FLOPs:5.27e+11 \n",
      "\n",
      "GFLOPs:527.1977984 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "!python -m train \\\n",
    "    --mode 'flops' \\\n",
    "    --train_eval_predict 'T_T_T' \\\n",
    "    --model_name 'demo_transformer_base' \\\n",
    "    --config './config/demo_transformer_base.json' \\\n",
    "    --data_dir './data/iwslt17.de.en/' \\\n",
    "    --txt_dir 'txt/' \\\n",
    "    --tokenizer_dir 'data/iwslt17.de.en/tokenizer' \\\n",
    "    --tokenizer_model_name 'transformer-sp-bpe-iwslt' \\\n",
    "    --encoding_type 'bpe' \\\n",
    "    --src_lang 'de' \\\n",
    "    --tgt_lang 'en' \\\n",
    "    --max_seq_length 50 \\\n",
    "    --vocab_size 37000 \\\n",
    "    --pad_id 0 \\\n",
    "    --unk_id 1 \\\n",
    "    --bos_id 2 \\\n",
    "    --eos_id 3 \\\n",
    "    --evaluation_metric 'bleu' \\\n",
    "    --seed 42 \\\n",
    "    --epoch 100 \\\n",
    "    --logging_step 100 \\\n",
    "    --gpu 0 \\\n",
    "    --batch_size 128 \\\n",
    "    --sinusoidal_wave 10000 \\\n",
    "    --embedding_dim 512 \\\n",
    "    --num_attention_heads 8 \\\n",
    "    --num_sub_layer 6 \\\n",
    "    --feed_forward_size 2048 \\\n",
    "    --attention_dropout_prob 0.1 \\\n",
    "    --label_smoothing 0.1 \\\n",
    "    --optimizer_coefficient 0.1 \\\n",
    "    --warmup_steps 4000 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --adam_beta1 0.9 \\\n",
    "    --adam_beta2 0.98 \\\n",
    "    --adam_epsilon 1e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Custom Dataset</b>\n",
    "<br><br>[IWSLT 2017-01](https://wit3.fbk.eu/2017-01)\n",
    "<br>[IWSLT 2017-01-B](https://wit3.fbk.eu/2017-01-b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer-Big (Noam Optimizer + Label Smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "!python -m train \\\n",
    "    --mode 'run' \\\n",
    "    --train_eval_predict 'T_T_T' \\\n",
    "    --loss_type 'label_smoothing' \\\n",
    "    --optimizer_type 'noam' \\\n",
    "    --model_name 'demo_transformer_base' \\\n",
    "    --config './config/demo_transformer_base.json' \\\n",
    "    --output_dir 'noam_label_smoothing_output/' \\\n",
    "    --data_dir './data/iwslt17.de.en/' \\\n",
    "    --txt_dir 'txt/' \\\n",
    "    --tokenizer_dir 'data/iwslt17.de.en/tokenizer' \\\n",
    "    --tokenizer_model_name 'transformer-sp-bpe-iwslt' \\\n",
    "    --encoding_type 'bpe' \\\n",
    "    --src_lang 'de' \\\n",
    "    --tgt_lang 'en' \\\n",
    "    --max_seq_length 50 \\\n",
    "    --vocab_size 37000 \\\n",
    "    --pad_id 0 \\\n",
    "    --unk_id 1 \\\n",
    "    --bos_id 2 \\\n",
    "    --eos_id 3 \\\n",
    "    --evaluation_metric 'bleu' \\\n",
    "    --seed 42 \\\n",
    "    --epoch 100 \\\n",
    "    --logging_step 1000000000 \\\n",
    "    --gpu 0 \\\n",
    "    --batch_size 128 \\\n",
    "    --sinusoidal_wave 10000 \\\n",
    "    --embedding_dim 1024 \\\n",
    "    --num_attention_heads 16 \\\n",
    "    --num_sub_layer 12 \\\n",
    "    --feed_forward_size 4096 \\\n",
    "    --attention_dropout_prob 0.3 \\\n",
    "    --label_smoothing 0.1 \\\n",
    "    --optimizer_coefficient 0.1 \\\n",
    "    --warmup_steps 4000 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --adam_beta1 0.9 \\\n",
    "    --adam_beta2 0.98 \\\n",
    "    --adam_epsilon 1e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer-Small (Noam Optimizer + Label Smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-22 12:41:22.150132: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-22 12:41:22.826113: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=./data/iwslt17.de.en/txt/train-de.txt,./data/iwslt17.de.en/txt/valid-de.txt --model_prefix=data/iwslt17.de.en/tokenizer/transformer-sp-bpe-iwslt-de --vocab_size=18500 --model_type=bpe --bos_id=2 --eos_id=3 --pad_id=0 --unk_id=1 --minloglevel=2\n",
      "Epoch 1: 100%|████████████████████████████████| 912/912 [02:30<00:00,  6.07it/s]\n",
      "\n",
      "\n",
      "Label: ['', 'Anyway', ',', 'that', 'piece', 'also', 'has', 'a', 'kin', 'etic', 'sculpture', 'in', 'the', 'middle', 'of', 'it', ',', 'and', 'I', 'dance', 'around', 'a', 'small', 'stage', 'so', '--', 'two', 'minutes', ',', 'just', 'to', 'end', '?', 'The', 'latest', 'piece', 'that', 'I', \"'\", 'm', 'working', 'on', '--', 'what', 'I', 'love', 'is', 'that', 'I', 'never']\n",
      "Prediction: ['', 'And', ',', 'I', 'I', ',', ',', ',', 'I', ',', ',', ',', 'the', 'I', ',', 'the', \"'\", 'and', 'I', \"'\", ',', ',', 'I', ',', ',', ',', 'the', ',', ',', 'and', ',', 'the', '.', '', '.', ',', '.', \"'\", \"'\", 's', '.', '.', 'the', 'the', '.', \"'\", ',', 'a', '.', \"'\"]\n",
      "Sentence Blue Score: 0.0 4\n",
      "Epoch 1: 100%|████████████████████████████████████| 7/7 [00:00<00:00, 12.08it/s]\n",
      "\n",
      "\n",
      "Label: ['is', 'that', 'with', 'a', 'lot', 'of', 'different', 'salad', 'dress', 'ings', 'to', 'choose', 'from', ',', 'if', 'you', 'buy', 'one', ',', 'and', 'it', \"'\", 's', 'not', 'perfect', '--', 'and', 'what', 'salad', 'dressing', 'is', '?', '--', 'it', \"'\", 's', 'easy', 'to', 'imagine', 'you', 'could', 'have', 'made', 'a', 'different', 'choice', 'that', 'would', 'have']\n",
      "Prediction: ['And', 'the', \"'\", 'the', \"'\", ',', 'the', ',', ',', ',', ',', 'the', ',', 'the', 'and', 'you', \"'\", ',', ',', 'and', 'the', \"'\", 's', 'a', ',', ',', 'the', 'the', 'to', ',', ',', 'the', '', 'the', \"'\", 's', 'a', ',', 'be', ',', \"'\", '.', 'the', '.', '', '.', '.', '.', '.']\n",
      "Sentence Blue Score: 0.0\n",
      "\n",
      "Epoch 1/100, Train Loss: 7.779, Validation Loss: 6.382\n",
      "\n",
      "Epoch 1: 100%|████████████████████████████████████| 9/9 [00:21<00:00,  2.35s/it]\n",
      "Test BLEU Score:0.0\n",
      "\n",
      "\n",
      "Epoch 2: 100%|████████████████████████████████| 912/912 [02:33<00:00,  5.96it/s]\n",
      "\n",
      "\n",
      "Label: ['', 'And', 'then', 'I', 'went', 'on', 'to', 'reflect', ',', '\"', 'Is', 'n', \"'\", 't', 'it', 'amazing', ',', 'this', 'entire', 'database', ',', 'all', 'these', 'recordings', ',', 'I', \"'\", 'm', 'going', 'to', 'hand', 'off', 'to', 'you', 'and', 'to', 'your', 'sister', '\"', '--', 'who', 'arrived', 'two', 'years', 'later', '--', '\"', 'and', 'you', 'guys']\n",
      "Prediction: ['', 'I', 'I', 'I', \"'\", 'and', 'the', 'the', ',', '\"', 'I', ',', ',', 's', 'know', \"'\", ',', '\"', ',', ',', ',', '\"', 'the', ',', ',', '\"', \"'\", 's', 'going', 'to', 'do', ',', ',', 'do', \"'\", 'I', 'the', 'life', ',', ',', 'and', \"'\", ',', '--', ',', ',', 'and', 'I', ',', \"'\"]\n",
      "Sentence Blue Score: 0.0 4\n",
      "Epoch 2: 100%|████████████████████████████████████| 7/7 [00:00<00:00, 11.01it/s]\n",
      "\n",
      "\n",
      "Label: ['is', 'that', 'with', 'a', 'lot', 'of', 'different', 'salad', 'dress', 'ings', 'to', 'choose', 'from', ',', 'if', 'you', 'buy', 'one', ',', 'and', 'it', \"'\", 's', 'not', 'perfect', '--', 'and', 'what', 'salad', 'dressing', 'is', '?', '--', 'it', \"'\", 's', 'easy', 'to', 'imagine', 'you', 'could', 'have', 'made', 'a', 'different', 'choice', 'that', 'would', 'have']\n",
      "Prediction: ['And', 'a', 'is', 'a', 'lot', 'of', 'the', 'of', 'that', ',', ',', 'be', ',', 'the', 'and', 'you', \"'\", ',', ',', 'and', 'you', \"'\", 's', 'not', 'a', ',', 'it', 'it', 'you', 'you', \"'\", 'a', '', 'it', \"'\", 's', 'not', 'you', 'do', ',', \"'\", 'be', 'a', 'you', 'lot', 'is', ',', 'you', 'be']\n",
      "Sentence Blue Score: 9.5376\n",
      "\n",
      "Epoch 2/100, Train Loss: 5.864, Validation Loss: 5.670\n",
      "\n",
      "Epoch 2: 100%|████████████████████████████████████| 9/9 [00:21<00:00,  2.35s/it]\n",
      "Test BLEU Score:1.18\n",
      "\n",
      "\n",
      "Epoch 3: 100%|████████████████████████████████| 912/912 [02:32<00:00,  5.99it/s]\n",
      "\n",
      "\n",
      "Label: ['', 'And', 'so', 'we', 'came', 'up', 'with', 'the', 'bright', 'idea', 'that', 'instead', 'of', 'getting', 'people', 'to', 'walk', '10,', '15', 'kilometers', 'to', 'see', 'doctors', ',', 'you', 'get', 'the', 'doctors', 'to', 'the', 'people', '.', 'And', 'we', 'started', 'engaging', 'the', 'medical', 'community', ',', 'and', 'you', 'know', ',', 'we', 'thought', 'we', 'were', 'real', 'bright']\n",
      "Prediction: ['', 'So', 'so', 'we', 'had', 'the', 'the', 'the', 'world', ',', 'of', 'people', 'people', 'people', 'people', 'to', 'be', 'to', 'to', 'to', 'to', 'the', 'the', 'to', 'and', 'know', 'to', 'other', 'to', 'be', 'way', 'to', 'And', 'so', \"'\", 'to', 'to', 'same', ',', 'to', 'and', 'I', 'know', ',', 'and', \"'\", ',', \"'\", 'going', 'to']\n",
      "Sentence Blue Score: 0.0 4\n",
      "Epoch 3: 100%|████████████████████████████████████| 7/7 [00:00<00:00, 12.55it/s]\n",
      "\n",
      "\n",
      "Label: ['is', 'that', 'with', 'a', 'lot', 'of', 'different', 'salad', 'dress', 'ings', 'to', 'choose', 'from', ',', 'if', 'you', 'buy', 'one', ',', 'and', 'it', \"'\", 's', 'not', 'perfect', '--', 'and', 'what', 'salad', 'dressing', 'is', '?', '--', 'it', \"'\", 's', 'easy', 'to', 'imagine', 'you', 'could', 'have', 'made', 'a', 'different', 'choice', 'that', 'would', 'have']\n",
      "Prediction: ['And', 'the', 'of', 'the', 'lot', 'of', 'the', ',', ',', ',', ',', 'the', ',', 'the', 'if', 'you', 'know', 'a', 'of', 'and', 'you', \"'\", 's', 'not', 'a', ',', 'and', 'it', 'it', 'is', 'is', '--', '', 'it', \"'\", 's', 'a', 'to', 'be', ',', 'know', 'be', 'a', 'a', 'lot', 'way', '?', '?', 'be']\n",
      "Sentence Blue Score: 11.603\n",
      "\n",
      "Epoch 3/100, Train Loss: 5.362, Validation Loss: 5.286\n",
      "\n",
      "Epoch 3: 100%|████████████████████████████████████| 9/9 [00:21<00:00,  2.38s/it]\n",
      "Test BLEU Score:2.2199\n",
      "\n",
      "\n",
      "Epoch 4: 100%|████████████████████████████████| 912/912 [02:33<00:00,  5.93it/s]\n",
      "\n",
      "\n",
      "Label: ['', 'So', ',', 'this', 'woman', ',', 'who', 'converted', 'from', 'the', 'Church', 'of', 'England', 'to', 'Catholic', 'ism', 'when', 'she', 'married', 'my', 'father', '--', 'and', 'there', \"'\", 's', 'no', 'one', 'more', 'rab', 'id', 'than', 'a', 'Catholic', 'convert', '--', 'decided', 'to', 'teach', 'in', 'the', 'rural', 'areas', 'in', 'Nigeria', ',', 'particularly', 'among', 'Igbo', 'women']\n",
      "Prediction: ['', 'So', ',', 'the', 'is', ',', 'the', 'are', 'of', 'the', 'most', 'of', 'the', ',', 'the', ',', ',', 'they', 'was', '--', 'mother', '--', 'and', 'it', \"'\", 's', 'a', 'one', 'of', 'of', '--', '--', 'the', 'lot', '--', '--', 'and', 'in', 'the', '--', 'the', 'same', ',', 'of', 'the', ',', 'and', '--', 'of', 'of']\n",
      "Sentence Blue Score: 0.0 4\n",
      "Epoch 4: 100%|████████████████████████████████████| 7/7 [00:00<00:00, 12.23it/s]\n",
      "\n",
      "\n",
      "Label: ['is', 'that', 'with', 'a', 'lot', 'of', 'different', 'salad', 'dress', 'ings', 'to', 'choose', 'from', ',', 'if', 'you', 'buy', 'one', ',', 'and', 'it', \"'\", 's', 'not', 'perfect', '--', 'and', 'what', 'salad', 'dressing', 'is', '?', '--', 'it', \"'\", 's', 'easy', 'to', 'imagine', 'you', 'could', 'have', 'made', 'a', 'different', 'choice', 'that', 'would', 'have']\n",
      "Prediction: ['And', 'a', 'one', 'them', 'lot', 'of', 'them', ',', 'that', ',', ',', 'the', ',', 'a', 'if', 'you', \"'\", 'a', ',', 'and', 'it', \"'\", 's', 'not', 'a', ',', 'and', 'it', 'it', 'is', 'is', 'not', 'It', 'it', \"'\", 's', 'a', 'to', 'be', 'that', \"'\", 'be', 'a', 'a', 'lot', '.', '?', 'you', 'be']\n",
      "Sentence Blue Score: 16.4791\n",
      "\n",
      "Epoch 4/100, Train Loss: 5.059, Validation Loss: 5.048\n",
      "\n",
      "Epoch 4: 100%|████████████████████████████████████| 9/9 [00:21<00:00,  2.41s/it]\n",
      "Test BLEU Score:3.7709\n",
      "\n",
      "\n",
      "Epoch 5: 100%|████████████████████████████████| 912/912 [02:33<00:00,  5.94it/s]\n",
      "\n",
      "\n",
      "Label: ['', 'One', 'is', 'that', '--', 'it', \"'\", 's', 'called', '\"', 'ge', 'ce', 'k', 'ond', 'u', '\"', 'in', 'Turkish', ',', 'which', 'means', '\"', 'built', 'overnight', ',\"', 'and', 'if', 'you', 'build', 'your', 'house', 'overnight', 'in', 'Turkey', ',', 'you', 'can', \"'\", 't', 'be', 'ev', 'icted', 'without', 'due', 'process', 'of', 'law', ',', 'if', 'they']\n",
      "Prediction: ['', 'The', 'thing', 'that', 'it', 'it', \"'\", 's', 'going', '\"', 'The', ',\"', ',\"', '\"', ',\"', ',\"', '--', '\"', ',', 'which', 'is', 'you', 'The', ',\"', ',\"', 'and', 'you', 'you', \"'\", 'the', 'house', 'and', 'and', 'the', ',', 'you', 'can', 'be', 't', 'get', 'able', ',', 'a', 'a', 'to', ',', 'the', ',', 'you', 'you']\n",
      "Sentence Blue Score: 0.0 4\n",
      "Epoch 5: 100%|████████████████████████████████████| 7/7 [00:00<00:00, 12.06it/s]\n",
      "\n",
      "\n",
      "Label: ['is', 'that', 'with', 'a', 'lot', 'of', 'different', 'salad', 'dress', 'ings', 'to', 'choose', 'from', ',', 'if', 'you', 'buy', 'one', ',', 'and', 'it', \"'\", 's', 'not', 'perfect', '--', 'and', 'what', 'salad', 'dressing', 'is', '?', '--', 'it', \"'\", 's', 'easy', 'to', 'imagine', 'you', 'could', 'have', 'made', 'a', 'different', 'choice', 'that', 'would', 'have']\n",
      "Prediction: ['One', 'from', 'of', 'them', 'big', 'of', 'the', ',', ',', ',', ',', 'the', 'the', 'a', 'if', 'you', \"'\", 'a', ',', 'and', 'it', \"'\", 's', 'not', 'a', ',', 'and', 'it', \"'\", 'is', 'is', ',', 'It', 'it', \"'\", 's', 'just', 'to', 'be', 'that', \"'\", 'be', 'a', 'a', 'big', 'way', '?', 'you', 'be']\n",
      "Sentence Blue Score: 15.2635\n",
      "\n",
      "Epoch 5/100, Train Loss: 4.835, Validation Loss: 4.858\n",
      "\n",
      "Epoch 5: 100%|████████████████████████████████████| 9/9 [00:21<00:00,  2.36s/it]\n",
      "Test BLEU Score:5.2817\n",
      "\n",
      "\n",
      "Epoch 6: 100%|████████████████████████████████| 912/912 [02:34<00:00,  5.90it/s]\n",
      "\n",
      "\n",
      "Label: ['And', 'so', 'even', 'though', 'the', 'universe', 'will', 'last', 'forever', ',', 'and', 'ordinary', 'matter', 'and', 'radiation', 'will', 'dil', 'ute', 'away', ',', 'there', 'will', 'always', 'be', 'some', 'radiation', ',', 'some', 'thermal', 'fluctuations', ',', 'even', 'in', 'empty', 'space', '.']\n",
      "Prediction: ['And', 'so', 'it', 'though', 'it', 'universe', 'is', 'be', 'the', 'and', 'and', 'it', ',', 'and', 'it', ',', 'be', ',', ',', ',', 'and', \"'\", 'be', 'be', 'a', 'of', ',', 'a', 'of', ',', ',', 'some', 'more', 'the', ',', ',']\n",
      "Sentence Blue Score: 0.0 4\n",
      "Epoch 6: 100%|████████████████████████████████████| 7/7 [00:00<00:00, 12.91it/s]\n",
      "\n",
      "\n",
      "Label: ['is', 'that', 'with', 'a', 'lot', 'of', 'different', 'salad', 'dress', 'ings', 'to', 'choose', 'from', ',', 'if', 'you', 'buy', 'one', ',', 'and', 'it', \"'\", 's', 'not', 'perfect', '--', 'and', 'what', 'salad', 'dressing', 'is', '?', '--', 'it', \"'\", 's', 'easy', 'to', 'imagine', 'you', 'could', 'have', 'made', 'a', 'different', 'choice', 'that', 'would', 'have']\n",
      "Prediction: ['One', 'by', 'one', 'them', 'big', 'of', 'different', 'ways', 'that', ',', ',', 'be', 'a', 'a', 'if', 'you', \"'\", 'a', ',', 'and', 'it', \"'\", 's', 'not', 'a', ',', 'and', 'it', \"'\", 'is', 'is', ',', 'It', 'it', \"'\", 's', 'just', 'to', 'be', ',', \"'\", 'be', 'a', 'a', 'better', 'way', '?', 'you', 'be']\n",
      "Sentence Blue Score: 15.8878\n",
      "\n",
      "Epoch 6/100, Train Loss: 4.652, Validation Loss: 4.719\n",
      "\n",
      "Epoch 6: 100%|████████████████████████████████████| 9/9 [00:21<00:00,  2.40s/it]\n",
      "Test BLEU Score:6.2505\n",
      "\n",
      "\n",
      "Epoch 7: 100%|████████████████████████████████| 912/912 [02:33<00:00,  5.93it/s]\n",
      "\n",
      "\n",
      "Label: ['', 'As', 'a', 'matter', 'of', 'fact', ',', 'we', 'think', 'reaching', '100', 'percent', 'is', 'very', 'doable', ',', 'even', 'before', 'the', '201', '5', 'time', 'frame', '.', 'In', 'other', 'parts', 'of', 'emerging', 'countries', ',', 'such', 'as', 'India', 'and', 'China', ',', 'the', 'progress', 'has', 'been', 'good', '--', 'has', 'been', 'solid', ',', 'has', 'been', 'good']\n",
      "Prediction: ['', 'In', 'we', 'moment', 'we', 'us', ',', 'we', 'believe', 'it', 'it', 'percent', 'of', 'to', ',', 'to', 'even', 'though', 'the', 'other', ',', ',', ',', ',', '', 'India', 'words', 'of', 'the', ',', ',', 'and', 'as', 'a', ',', 'China', 'were', 'and', 'good', ',', 'been', 'good', ',', 'and', 'been', 'good', 'in', 'but', 'not', 'good']\n",
      "Sentence Blue Score: 0.0 4\n",
      "Epoch 7: 100%|████████████████████████████████████| 7/7 [00:00<00:00, 12.38it/s]\n",
      "\n",
      "\n",
      "Label: ['is', 'that', 'with', 'a', 'lot', 'of', 'different', 'salad', 'dress', 'ings', 'to', 'choose', 'from', ',', 'if', 'you', 'buy', 'one', ',', 'and', 'it', \"'\", 's', 'not', 'perfect', '--', 'and', 'what', 'salad', 'dressing', 'is', '?', '--', 'it', \"'\", 's', 'easy', 'to', 'imagine', 'you', 'could', 'have', 'made', 'a', 'different', 'choice', 'that', 'would', 'have']\n",
      "Prediction: ['One', 'one', 'one', 'them', 'great', 'of', 'them', 'ways', 'the', ',', 'different', 'be', 'a', 'different', 'if', 'you', 'buy', 'a', ',', 'and', 'it', \"'\", 's', 'not', 'a', ',', 'and', 'it', \"'\", 'is', 'is', 'it', 'It', 'it', \"'\", 's', 'just', 'to', 'be', 'that', \"'\", 'be', 'a', 'a', 'little', 'way', '?', 'you', 'be']\n",
      "Sentence Blue Score: 17.4176\n",
      "\n",
      "Epoch 7/100, Train Loss: 4.509, Validation Loss: 4.586\n",
      "\n",
      "Epoch 7: 100%|████████████████████████████████████| 9/9 [00:21<00:00,  2.40s/it]\n",
      "Test BLEU Score:7.6331\n",
      "\n",
      "\n",
      "Epoch 8: 100%|████████████████████████████████| 912/912 [02:35<00:00,  5.87it/s]\n",
      "\n",
      "\n",
      "Label: ['', 'All', 'these', 'people', 'that', 'had', 'sort', 'of', 'flexible', 'daily', 'hours', 'and', 'an', 'interest', 'in', 'the', 'English', 'word', '--', 'I', 'hope', 'to', 'have', 'an', 'interest', 'in', 'the', 'English', 'language', ',', 'but', 'I', \"'\", 'm', 'not', 'speaking', 'it', 'well', 'right', 'now', '.', 'I', \"'\", 'm', 'trying', '.', 'That', 'clock', 'has', 'got']\n",
      "Prediction: ['', 'All', 'these', 'people', 'have', 'have', 'to', 'of', 'a', '-', '-', ',', 'a', 'opportunity', 'in', 'the', 'language', 'language', '--', 'I', 'hope', 'to', 'have', 'a', 'opportunity', 'of', 'the', 'language', ',', ',', 'but', 'I', \"'\", 'm', 'not', 'really', 'to', '.', '.', 'now', '.', 'I', \"'\", 'm', 'not', 'to', 'I', \"'\", '.', 'my']\n",
      "Sentence Blue Score: 28.3235 4\n",
      "Epoch 8: 100%|████████████████████████████████████| 7/7 [00:00<00:00, 12.30it/s]\n",
      "\n",
      "\n",
      "Label: ['is', 'that', 'with', 'a', 'lot', 'of', 'different', 'salad', 'dress', 'ings', 'to', 'choose', 'from', ',', 'if', 'you', 'buy', 'one', ',', 'and', 'it', \"'\", 's', 'not', 'perfect', '--', 'and', 'what', 'salad', 'dressing', 'is', '?', '--', 'it', \"'\", 's', 'easy', 'to', 'imagine', 'you', 'could', 'have', 'made', 'a', 'different', 'choice', 'that', 'would', 'have']\n",
      "Prediction: ['One', 'one', 'one', 'them', 'great', 'of', 'them', 'things', 'the', ',', ',', 'be', 'a', 'a', 'if', 'you', 'buy', 'a', ',', 'and', 'it', \"'\", 's', 'not', 'a', ',', 'and', 'it', \"'\", 'is', 'is', ',', 'It', 'it', \"'\", 's', 'just', 'to', 'be', 'that', \"'\", 'be', 'a', 'a', 'better', 'idea', '?', 'you', 'be']\n",
      "Sentence Blue Score: 16.6287\n",
      "\n",
      "Epoch 8/100, Train Loss: 4.389, Validation Loss: 4.488\n",
      "\n",
      "Epoch 8: 100%|████████████████████████████████████| 9/9 [00:21<00:00,  2.37s/it]\n",
      "Test BLEU Score:8.6554\n",
      "\n",
      "\n",
      "Epoch 9: 100%|████████████████████████████████| 912/912 [02:34<00:00,  5.90it/s]\n",
      "\n",
      "\n",
      "Label: ['', 'And', 'I', \"'\", 'm', 'saying', 'this', 'as', 'an', 'economist', 'who', ',', 'over', 'the', 'past', 'few', 'years', ',', 'has', 'focused', 'my', 'research', 'on', 'what', 'it', 'is', 'we', 'think', 'and', 'who', 'it', 'is', 'we', 'trust', 'and', 'why', ',', 'but', 'also', '--', 'and', 'I', \"'\", 'm', 'aware', 'of', 'the', 'irony', 'here', '--']\n",
      "Prediction: ['', 'And', 'I', \"'\", 'm', 'going', 'to', 'as', 'a', 'oil', 'that', 'has', 'which', 'the', 'years', 'years', 'years', ',', 'which', 'been', 'on', 'age', ',', 'the', 'we', 'and', ',', 'think', 'and', 'why', 'we', \"'\", ',', 'think', 'and', 'why', 'I', 'and', 'I', 'I', 'I', 'I', \"'\", 'm', 'going', 'of', 'the', 'way', '--', '--']\n",
      "Sentence Blue Score: 11.1289 4\n",
      "Epoch 9: 100%|████████████████████████████████████| 7/7 [00:00<00:00, 12.04it/s]\n",
      "\n",
      "\n",
      "Label: ['is', 'that', 'with', 'a', 'lot', 'of', 'different', 'salad', 'dress', 'ings', 'to', 'choose', 'from', ',', 'if', 'you', 'buy', 'one', ',', 'and', 'it', \"'\", 's', 'not', 'perfect', '--', 'and', 'what', 'salad', 'dressing', 'is', '?', '--', 'it', \"'\", 's', 'easy', 'to', 'imagine', 'you', 'could', 'have', 'made', 'a', 'different', 'choice', 'that', 'would', 'have']\n",
      "Prediction: ['One', 'one', 'one', 'them', 'lot', 'of', 'them', 'ways', ',', ',', 'different', 'be', 'a', 'different', 'if', 'you', 'buy', 'a', ',', 'and', 'it', \"'\", 's', 'not', 'a', ',', 'and', 'it', \"'\", 'is', 'is', ',', 'It', 'it', \"'\", 's', 'just', 'to', 'be', 'that', \"'\", 'be', 'a', 'a', 'decision', 'decision', '?', 'you', 'be']\n",
      "Sentence Blue Score: 18.0067\n",
      "\n",
      "Epoch 9/100, Train Loss: 4.288, Validation Loss: 4.386\n",
      "\n",
      "Epoch 9: 100%|████████████████████████████████████| 9/9 [00:21<00:00,  2.39s/it]\n",
      "Test BLEU Score:9.3825\n",
      "\n",
      "\n",
      "Epoch 10: 100%|███████████████████████████████| 912/912 [02:35<00:00,  5.87it/s]\n",
      "\n",
      "\n",
      "Label: ['', 'So', 'if', 'you', 'are', 'concerned', 'to', 'influence', 'energy', 'policy', ',', 'or', 'you', 'are', 'concerned', 'to', 'influence', 'national', 'security', 'policy', ',', 'or', 'health', 'policy', ',', 'or', 'education', ',', 'science', '--', 'and', 'a', 'particular', 'branch', 'of', 'science', '--', 'is', 'a', 'way', 'to', 'do', 'it', ',', 'not', 'the', 'way', 'we', \"'\", 've']\n",
      "Prediction: ['', 'So', 'if', 'you', 'want', 'the', 'about', 'the', ',', ',', ',', 'or', 'if', 'want', 'the', 'about', 'the', 'the', ',', ',', ',', 'or', 'the', ',', ',', 'you', 'the', ',', 'you', 'is', 'is', 'the', 'very', ',', ',', 'science', ',', 'that', 'a', 'very', 'of', 'do', 'this', ',', 'and', 'a', 'way', 'of', 'do', 's']\n",
      "Sentence Blue Score: 0.0 4\n",
      "Epoch 10: 100%|███████████████████████████████████| 7/7 [00:00<00:00, 11.73it/s]\n",
      "\n",
      "\n",
      "Label: ['is', 'that', 'with', 'a', 'lot', 'of', 'different', 'salad', 'dress', 'ings', 'to', 'choose', 'from', ',', 'if', 'you', 'buy', 'one', ',', 'and', 'it', \"'\", 's', 'not', 'perfect', '--', 'and', 'what', 'salad', 'dressing', 'is', '?', '--', 'it', \"'\", 's', 'easy', 'to', 'imagine', 'you', 'could', 'have', 'made', 'a', 'different', 'choice', 'that', 'would', 'have']\n",
      "Prediction: ['One', 'one', 'one', 'them', 'great', 'of', 'them', 'things', ',', ',', ',', 'be', 'if', 'a', 'if', 'you', 'buy', 'a', ',', 'and', 'it', \"'\", 's', 'not', 'a', '--', 'and', 'it', \"'\", 'is', 'is', ',', 'It', 'it', \"'\", 's', 'easy', 'to', 'be', 'that', \"'\", 'be', 'a', 'a', 'decision', 'decision', '?', 'you', 'be']\n",
      "Sentence Blue Score: 22.2577\n",
      "\n",
      "Epoch 10/100, Train Loss: 4.201, Validation Loss: 4.322\n",
      "\n",
      "Epoch 10: 100%|███████████████████████████████████| 9/9 [00:21<00:00,  2.39s/it]\n",
      "Test BLEU Score:9.6504\n",
      "\n",
      "\n",
      "Epoch 11: 100%|███████████████████████████████| 912/912 [02:35<00:00,  5.86it/s]\n",
      "\n",
      "\n",
      "Label: ['', 'So', 'since', 'I', \"'\", 've', 'had', 'this', 'result', ',', 'I', \"'\", 've', 'spent', 'a', 'lot', 'of', 'time', 'trying', 'to', 'figure', 'out', 'what', 'kinds', 'of', 'decision', 'rules', '--', 'very', 'simple', ',', 'local', ',', 'probably', 'o', 'lf', 'act', 'ory', ',', 'chemical', 'rules', 'could', 'an', 'ant', 'could', 'be', 'using', ',', 'since', 'no']\n",
      "Prediction: ['', 'So', 'I', 'I', 'have', 've', 'been', 'this', 'kind', ',', 'so', \"'\", 've', 'been', 'a', 'lot', 'of', 'time', 'to', 'to', 'figure', 'out', 'what', \"'\", 'of', ',', '--', '--', 'very', 'simple', ',', 'very', ',', 'very', ',', ',', ',', ',', ',', 'a', ',', ',', 'use', 'act', \"'\", 'use', 'able', 'the', 'and', 'the']\n",
      "Sentence Blue Score: 17.4176 4\n",
      "Epoch 11: 100%|███████████████████████████████████| 7/7 [00:00<00:00, 11.92it/s]\n",
      "\n",
      "\n",
      "Label: ['is', 'that', 'with', 'a', 'lot', 'of', 'different', 'salad', 'dress', 'ings', 'to', 'choose', 'from', ',', 'if', 'you', 'buy', 'one', ',', 'and', 'it', \"'\", 's', 'not', 'perfect', '--', 'and', 'what', 'salad', 'dressing', 'is', '?', '--', 'it', \"'\", 's', 'easy', 'to', 'imagine', 'you', 'could', 'have', 'made', 'a', 'different', 'choice', 'that', 'would', 'have']\n",
      "Prediction: ['One', 'one', 'one', 'them', 'lot', 'of', 'them', 'ways', 'different', ',', ',', 'be', 'if', 'a', 'if', 'you', 'buy', 'a', ',', 'and', 'it', \"'\", 's', 'not', 'a', '--', 'and', 'it', 'it', 'is', 'is', 'it', 'It', 'it', \"'\", 's', 'just', 'to', 'be', 'that', 'have', 'be', 'a', 'a', 'decision', 'decision', '?', 'you', 'be']\n",
      "Sentence Blue Score: 18.1712\n",
      "\n",
      "Epoch 11/100, Train Loss: 4.126, Validation Loss: 4.255\n",
      "\n",
      "Epoch 11: 100%|███████████████████████████████████| 9/9 [00:21<00:00,  2.43s/it]\n",
      "Test BLEU Score:10.26\n",
      "\n",
      "\n",
      "Epoch 12: 100%|███████████████████████████████| 912/912 [02:35<00:00,  5.87it/s]\n",
      "\n",
      "\n",
      "Label: ['', 'At', 'Acumen', 'Fund', ',', 'we', 'take', 'philanthropic', 'resources', 'and', 'we', 'invest', 'what', 'we', 'call', 'patient', 'capital', '--', 'money', 'that', 'will', 'invest', 'in', 'entrepreneurs', 'who', 'see', 'the', 'poor', 'not', 'as', 'passive', 'recip', 'ients', 'of', 'charity', ',', 'but', 'as', 'full', '-', 'b', 'odied', 'agents', 'of', 'change', 'who', 'want', 'to', 'solve', 'their']\n",
      "Prediction: ['', 'In', 'the', ',', ',', 'where', 'take', 'where', ',', 'and', 'the', \"'\", 'what', 'we', 'call', 'a', '--', '--', 'money', ',', 'will', 'be', 'in', 'the', ',', 'don', 'the', 'poor', ',', 'as', 'a', ',', 'ate', 'as', 'the', ',', 'but', 'as', 'a', 'of', 'like', '-', ',', ',', 'the', 'as', 'are', 'to', 'look', 'as']\n",
      "Sentence Blue Score: 0.0 4\n",
      "Epoch 12: 100%|███████████████████████████████████| 7/7 [00:00<00:00, 11.19it/s]\n",
      "\n",
      "\n",
      "Label: ['is', 'that', 'with', 'a', 'lot', 'of', 'different', 'salad', 'dress', 'ings', 'to', 'choose', 'from', ',', 'if', 'you', 'buy', 'one', ',', 'and', 'it', \"'\", 's', 'not', 'perfect', '--', 'and', 'what', 'salad', 'dressing', 'is', '?', '--', 'it', \"'\", 's', 'easy', 'to', 'imagine', 'you', 'could', 'have', 'made', 'a', 'different', 'choice', 'that', 'would', 'have']\n",
      "Prediction: ['One', 'one', 'one', 'them', 'great', 'of', 'them', 'kinds', 'different', ',', ',', 'be', 'when', 'one', 'if', 'you', 'buy', 'a', ',', 'and', 'it', \"'\", 's', 'not', 'a', '--', 'and', 'it', \"'\", 'is', 'is', ',', 'It', 'it', \"'\", 's', 'just', 'to', 'be', 'that', '.', 'be', 'a', 'a', 'decision', 'decision', '?', 'you', 'be']\n",
      "Sentence Blue Score: 17.4176\n",
      "\n",
      "Epoch 12/100, Train Loss: 4.059, Validation Loss: 4.199\n",
      "\n",
      "Epoch 12: 100%|███████████████████████████████████| 9/9 [00:21<00:00,  2.41s/it]\n",
      "Test BLEU Score:10.8434\n",
      "\n",
      "\n",
      "Epoch 13: 100%|███████████████████████████████| 912/912 [02:35<00:00,  5.86it/s]\n",
      "\n",
      "\n",
      "Label: ['', 'Once', 'you', \"'\", 're', 'in', 'orbit', ',', 'you', 'are', 'two', 'thirds', 'of', 'the', 'way', ',', 'energet', 'ically', ',', 'to', 'anywhere', '--', 'the', 'moon', ',', 'to', 'Mars', '.', 'And', 'today', ',', 'there', \"'\", 's', 'only', 'three', 'vehicles', '--', 'the', 'U', '.', 'S', '.', 'shuttle', ',', 'the', 'Russian', 'So', 'y', 'uz']\n",
      "Prediction: ['', 'In', ',', 'have', 've', 'in', 'the', ',', 'we', 'know', '--', '--', '--', 'energy', 'energy', '--', 'two', '-', ',', 'two', 'the', ',', 'two', 'same', 'of', 'the', 'the', ',', 'There', 'there', ',', 'there', 'are', 's', 'only', 'three', '-', '--', 'the', 'U', '.', 'S', '.', 'S', '.', 'the', 'U', ',', ',', ',']\n",
      "Sentence Blue Score: 16.0507 4\n",
      "Epoch 13: 100%|███████████████████████████████████| 7/7 [00:00<00:00, 12.15it/s]\n",
      "\n",
      "\n",
      "Label: ['is', 'that', 'with', 'a', 'lot', 'of', 'different', 'salad', 'dress', 'ings', 'to', 'choose', 'from', ',', 'if', 'you', 'buy', 'one', ',', 'and', 'it', \"'\", 's', 'not', 'perfect', '--', 'and', 'what', 'salad', 'dressing', 'is', '?', '--', 'it', \"'\", 's', 'easy', 'to', 'imagine', 'you', 'could', 'have', 'made', 'a', 'different', 'choice', 'that', 'would', 'have']\n",
      "Prediction: ['One', 'one', 'one', 'them', 'lot', 'of', 'them', 'kinds', ',', ',', ',', 'be', 'when', 'one', 'if', 'you', 'buy', 'one', ',', 'and', 'it', \"'\", 's', 'not', 'a', '--', 'and', 'it', \"'\", 'is', 'is', ',', 'It', 'it', \"'\", 's', 'just', 'to', 'be', 'that', \"'\", 'be', 'a', 'a', 'decision', 'decision', '?', 'you', 'be']\n",
      "Sentence Blue Score: 25.4385\n",
      "\n",
      "Epoch 13/100, Train Loss: 4.000, Validation Loss: 4.143\n",
      "\n",
      "Epoch 13: 100%|███████████████████████████████████| 9/9 [00:21<00:00,  2.41s/it]\n",
      "Test BLEU Score:11.133\n",
      "\n",
      "\n",
      "Epoch 14: 100%|███████████████████████████████| 912/912 [02:36<00:00,  5.84it/s]\n",
      "\n",
      "\n",
      "Label: ['', 'Do', 'you', 'realize', 'that', 'we', 'could', 'change', 'the', 'capacity', 'of', 'highways', 'by', 'a', 'factor', 'of', 'two', 'or', 'three', 'if', 'we', 'didn', \"'\", 't', 'rely', 'on', 'human', 'precision', 'on', 'staying', 'in', 'the', 'lane', '--', 'improve', 'body', 'position', 'and', 'therefore', 'drive', 'a', 'little', 'bit', 'closer', 'together', 'on', 'a', 'little', 'bit', 'narrow']\n",
      "Prediction: ['', 'Is', 'you', 'think', 'that', 'we', 'could', 'get', 'the', 'trees', 'of', 'the', 'or', 'the', 'human', ',', 'the', 'or', 'the', 'times', 'we', 'don', \"'\", 't', 'go', 'on', 'human', 'beings', ',', 'the', '?', 'order', 'order', '?', 'if', 'the', '.', 'of', 'you', 'the', 'the', 'position', 'bit', 'of', 'to', '?', 'the', 'lot', 'bit', 'of']\n",
      "Sentence Blue Score: 0.0 4\n",
      "Epoch 14: 100%|███████████████████████████████████| 7/7 [00:00<00:00, 11.98it/s]\n",
      "\n",
      "\n",
      "Label: ['is', 'that', 'with', 'a', 'lot', 'of', 'different', 'salad', 'dress', 'ings', 'to', 'choose', 'from', ',', 'if', 'you', 'buy', 'one', ',', 'and', 'it', \"'\", 's', 'not', 'perfect', '--', 'and', 'what', 'salad', 'dressing', 'is', '?', '--', 'it', \"'\", 's', 'easy', 'to', 'imagine', 'you', 'could', 'have', 'made', 'a', 'different', 'choice', 'that', 'would', 'have']\n",
      "Prediction: ['One', 'one', 'one', 'them', 'lot', 'of', 'them', 'kinds', ',', ',', ',', 'be', 'if', 'one', 'if', 'you', 'buy', 'one', ',', 'and', 'it', \"'\", 's', 'not', 'a', '--', 'and', 'it', \"'\", 'is', 'is', 'that', 'It', 'it', \"'\", 's', 'just', 'to', 'be', 'that', 'have', 'be', 'a', 'a', 'decision', 'decision', '.', 'you', 'be']\n",
      "Sentence Blue Score: 26.1598\n",
      "\n",
      "Epoch 14/100, Train Loss: 3.947, Validation Loss: 4.105\n",
      "\n",
      "Epoch 14: 100%|███████████████████████████████████| 9/9 [00:21<00:00,  2.39s/it]\n",
      "Test BLEU Score:11.4489\n",
      "\n",
      "\n",
      "Epoch 15: 100%|███████████████████████████████| 912/912 [02:36<00:00,  5.84it/s]\n",
      "\n",
      "\n",
      "Label: ['', 'In', '2004,', 'there', 'were', 'only', 'two', 'flights', ':', 'two', 'Russian', 'So', 'y', 'uz', 'flights', 'to', 'the', 'international', 'man', 'ned', 'station', '.', 'And', 'I', 'had', 'to', 'fly', 'three', 'in', 'Mo', 'j', 'ave', 'with', 'my', 'little', 'group', 'of', 'a', 'couple', 'dozen', 'people', 'in', 'order', 'to', 'get', 'to', 'a', 'total', 'of', 'five']\n",
      "Prediction: ['', 'In', 'fact', ',', 'were', 'only', 'two', 'tons', ':', 'with', '-', '-', ',', '-', ',', ',', 'the', 'top', 'space', ',', ',', ',', 'And', 'I', 'had', 'to', 'do', 'in', '-', 'the', 'ig', 'ab', 'with', 'my', 'three', 'bit', ',', 'three', 'few', 'of', ',', ',', 'so', 'to', 'do', 'five', 'five', 'few', '.', 'three']\n",
      "Sentence Blue Score: 8.873 4\n",
      "Epoch 15: 100%|███████████████████████████████████| 7/7 [00:00<00:00, 12.62it/s]\n",
      "\n",
      "\n",
      "Label: ['is', 'that', 'with', 'a', 'lot', 'of', 'different', 'salad', 'dress', 'ings', 'to', 'choose', 'from', ',', 'if', 'you', 'buy', 'one', ',', 'and', 'it', \"'\", 's', 'not', 'perfect', '--', 'and', 'what', 'salad', 'dressing', 'is', '?', '--', 'it', \"'\", 's', 'easy', 'to', 'imagine', 'you', 'could', 'have', 'made', 'a', 'different', 'choice', 'that', 'would', 'have']\n",
      "Prediction: ['One', 'one', 'one', 'them', 'lot', 'of', 'them', 'ways', ',', ',', ',', 'be', 'if', 'one', 'if', 'you', 'buy', 'one', ',', 'and', 'it', \"'\", 's', 'not', 'perfect', '--', 'and', 'it', \"'\", 'is', 'is', ',', 'It', 'it', \"'\", 's', 'just', 'to', 'be', 'that', \"'\", 'be', 'a', 'a', 'decision', 'decision', '?', 'you', 'be']\n",
      "Sentence Blue Score: 31.267\n",
      "\n",
      "Epoch 15/100, Train Loss: 3.900, Validation Loss: 4.067\n",
      "\n",
      "Epoch 15: 100%|███████████████████████████████████| 9/9 [00:21<00:00,  2.39s/it]\n",
      "Test BLEU Score:11.5688\n",
      "\n",
      "\n",
      "Epoch 16:  50%|███████████████▋               | 460/912 [01:18<01:16,  5.89it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "!python -m train \\\n",
    "    --mode 'run' \\\n",
    "    --train_eval_predict 'T_T_T' \\\n",
    "    --loss_type 'label_smoothing' \\\n",
    "    --optimizer_type 'noam' \\\n",
    "    --model_name 'demo_transformer_base' \\\n",
    "    --config './config/demo_transformer_base.json' \\\n",
    "    --output_dir 'noam_label_smoothing_output/' \\\n",
    "    --data_dir './data/iwslt17.de.en/' \\\n",
    "    --txt_dir 'txt/' \\\n",
    "    --tokenizer_dir 'data/iwslt17.de.en/tokenizer' \\\n",
    "    --tokenizer_model_name 'transformer-sp-bpe-iwslt' \\\n",
    "    --encoding_type 'bpe' \\\n",
    "    --src_lang 'de' \\\n",
    "    --tgt_lang 'en' \\\n",
    "    --max_seq_length 50 \\\n",
    "    --vocab_size 37000 \\\n",
    "    --pad_id 0 \\\n",
    "    --unk_id 1 \\\n",
    "    --bos_id 2 \\\n",
    "    --eos_id 3 \\\n",
    "    --evaluation_metric 'bleu' \\\n",
    "    --seed 42 \\\n",
    "    --epoch 100 \\\n",
    "    --logging_step 1000000000 \\\n",
    "    --gpu 0 \\\n",
    "    --batch_size 128 \\\n",
    "    --sinusoidal_wave 10000 \\\n",
    "    --embedding_dim 512 \\\n",
    "    --num_attention_heads 8 \\\n",
    "    --num_sub_layer 6 \\\n",
    "    --feed_forward_size 2048 \\\n",
    "    --attention_dropout_prob 0.1 \\\n",
    "    --label_smoothing 0.1 \\\n",
    "    --optimizer_coefficient 0.1 \\\n",
    "    --warmup_steps 4000 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --adam_beta1 0.9 \\\n",
    "    --adam_beta2 0.98 \\\n",
    "    --adam_epsilon 1e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer-Small (Noam Optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "!python -m train \\\n",
    "    --mode 'run' \\\n",
    "    --train_eval_predict 'T_T_T' \\\n",
    "    --loss_type 'not_label_smoothing' \\\n",
    "    --optimizer_type 'noam' \\\n",
    "    --model_name 'demo_transformer_base' \\\n",
    "    --config './config/demo_transformer_base.json' \\\n",
    "    --output_dir 'noam_output/' \\\n",
    "    --data_dir './data/iwslt17.de.en/' \\\n",
    "    --txt_dir 'txt/' \\\n",
    "    --tokenizer_dir 'data/iwslt17.de.en/tokenizer' \\\n",
    "    --tokenizer_model_name 'transformer-sp-bpe-iwslt' \\\n",
    "    --encoding_type 'bpe' \\\n",
    "    --src_lang 'de' \\\n",
    "    --tgt_lang 'en' \\\n",
    "    --max_seq_length 50 \\\n",
    "    --vocab_size 37000 \\\n",
    "    --pad_id 0 \\\n",
    "    --unk_id 1 \\\n",
    "    --bos_id 2 \\\n",
    "    --eos_id 3 \\\n",
    "    --evaluation_metric 'bleu' \\\n",
    "    --seed 42 \\\n",
    "    --epoch 100 \\\n",
    "    --logging_step 1000000000 \\\n",
    "    --gpu 0 \\\n",
    "    --batch_size 128 \\\n",
    "    --sinusoidal_wave 10000 \\\n",
    "    --embedding_dim 512 \\\n",
    "    --num_attention_heads 8 \\\n",
    "    --num_sub_layer 6 \\\n",
    "    --feed_forward_size 2048 \\\n",
    "    --attention_dropout_prob 0.1 \\\n",
    "    --label_smoothing 0.1 \\\n",
    "    --optimizer_coefficient 0.1 \\\n",
    "    --warmup_steps 4000 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --adam_beta1 0.9 \\\n",
    "    --adam_beta2 0.98 \\\n",
    "    --adam_epsilon 1e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer-Small (Adam Optimizer + Label Smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "!python -m train \\\n",
    "    --mode 'run' \\\n",
    "    --train_eval_predict 'T_T_T' \\\n",
    "    --loss_type 'label_smoothing' \\\n",
    "    --optimizer_type 'adam' \\\n",
    "    --model_name 'demo_transformer_base' \\\n",
    "    --config './config/demo_transformer_base.json' \\\n",
    "    --output_dir 'adam_label_smoothing_output/' \\\n",
    "    --data_dir './data/iwslt17.de.en/' \\\n",
    "    --txt_dir 'txt/' \\\n",
    "    --tokenizer_dir 'data/iwslt17.de.en/tokenizer' \\\n",
    "    --tokenizer_model_name 'transformer-sp-bpe-iwslt' \\\n",
    "    --encoding_type 'bpe' \\\n",
    "    --src_lang 'de' \\\n",
    "    --tgt_lang 'en' \\\n",
    "    --max_seq_length 50 \\\n",
    "    --vocab_size 37000 \\\n",
    "    --pad_id 0 \\\n",
    "    --unk_id 1 \\\n",
    "    --bos_id 2 \\\n",
    "    --eos_id 3 \\\n",
    "    --evaluation_metric 'bleu' \\\n",
    "    --seed 42 \\\n",
    "    --epoch 100 \\\n",
    "    --logging_step 1000000000 \\\n",
    "    --gpu 0 \\\n",
    "    --batch_size 128 \\\n",
    "    --sinusoidal_wave 10000 \\\n",
    "    --embedding_dim 512 \\\n",
    "    --num_attention_heads 8 \\\n",
    "    --num_sub_layer 6 \\\n",
    "    --feed_forward_size 2048 \\\n",
    "    --attention_dropout_prob 0.1 \\\n",
    "    --label_smoothing 0.1 \\\n",
    "    --optimizer_coefficient 0.1 \\\n",
    "    --warmup_steps 4000 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --adam_beta1 0.9 \\\n",
    "    --adam_beta2 0.98 \\\n",
    "    --adam_epsilon 1e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer-Small (Adam Optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "!python -m train \\\n",
    "    --mode 'run' \\\n",
    "    --train_eval_predict 'T_T_T' \\\n",
    "    --loss_type 'not_label_smoothing' \\\n",
    "    --optimizer_type 'adam' \\\n",
    "    --model_name 'demo_transformer_base' \\\n",
    "    --config './config/demo_transformer_base.json' \\\n",
    "    --output_dir 'adam_output/' \\\n",
    "    --data_dir './data/iwslt17.de.en/' \\\n",
    "    --txt_dir 'txt/' \\\n",
    "    --tokenizer_dir 'data/iwslt17.de.en/tokenizer' \\\n",
    "    --tokenizer_model_name 'transformer-sp-bpe-iwslt' \\\n",
    "    --encoding_type 'bpe' \\\n",
    "    --src_lang 'de' \\\n",
    "    --tgt_lang 'en' \\\n",
    "    --max_seq_length 50 \\\n",
    "    --vocab_size 37000 \\\n",
    "    --pad_id 0 \\\n",
    "    --unk_id 1 \\\n",
    "    --bos_id 2 \\\n",
    "    --eos_id 3 \\\n",
    "    --evaluation_metric 'bleu' \\\n",
    "    --seed 42 \\\n",
    "    --epoch 100 \\\n",
    "    --logging_step 1000000000 \\\n",
    "    --gpu 0 \\\n",
    "    --batch_size 128 \\\n",
    "    --sinusoidal_wave 10000 \\\n",
    "    --embedding_dim 512 \\\n",
    "    --num_attention_heads 8 \\\n",
    "    --num_sub_layer 6 \\\n",
    "    --feed_forward_size 2048 \\\n",
    "    --attention_dropout_prob 0.1 \\\n",
    "    --label_smoothing 0.1 \\\n",
    "    --optimizer_coefficient 0.1 \\\n",
    "    --warmup_steps 4000 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --adam_beta1 0.9 \\\n",
    "    --adam_beta2 0.98 \\\n",
    "    --adam_epsilon 1e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Huggingface Dataset</b>\n",
    "<br><br>[iwslt2017](https://huggingface.co/datasets/iwslt2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "!python -m train \\\n",
    "    --mode 'run' \\\n",
    "    --train_eval_predict 'T_T_T' \\\n",
    "    --loss_type 'not_label_smoothing' \\\n",
    "    --optimizer_type 'adam' \\\n",
    "    --model_name 'demo_transformer_base' \\\n",
    "    --config './config/demo_transformer_base.json' \\\n",
    "    --output_dir 'huggingface_output/' \\\n",
    "    --data_dir './data/iwslt17.de.en/' \\\n",
    "    --txt_dir 'huggingface_txt/' \\\n",
    "    --tokenizer_dir 'data/iwslt17.de.en/tokenizer' \\\n",
    "    --tokenizer_model_name 'transformer-sp-bpe-iwslt' \\\n",
    "    --encoding_type 'bpe' \\\n",
    "    --src_lang 'de' \\\n",
    "    --tgt_lang 'en' \\\n",
    "    --max_seq_length 50 \\\n",
    "    --vocab_size 37000 \\\n",
    "    --pad_id 0 \\\n",
    "    --unk_id 1 \\\n",
    "    --bos_id 2 \\\n",
    "    --eos_id 3 \\\n",
    "    --evaluation_metric 'bleu' \\\n",
    "    --seed 42 \\\n",
    "    --epoch 100 \\\n",
    "    --logging_step 1000000000 \\\n",
    "    --gpu 0 \\\n",
    "    --batch_size 128 \\\n",
    "    --sinusoidal_wave 10000 \\\n",
    "    --embedding_dim 512 \\\n",
    "    --num_attention_heads 8 \\\n",
    "    --num_sub_layer 6 \\\n",
    "    --feed_forward_size 2048 \\\n",
    "    --attention_dropout_prob 0.1 \\\n",
    "    --label_smoothing 0.1 \\\n",
    "    --optimizer_coefficient 0.1 \\\n",
    "    --warmup_steps 4000 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --adam_beta1 0.9 \\\n",
    "    --adam_beta2 0.98 \\\n",
    "    --adam_epsilon 1e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Paper</b>\n",
    "<br>[Attention is all you need](https://arxiv.org/abs/1706.03762)\n",
    "\n",
    "<br><b>Data</b>\n",
    "<br>[IWSLT 2017-01](https://wit3.fbk.eu/2017-01)\n",
    "<br>[IWSLT 2017-01-B](https://wit3.fbk.eu/2017-01-b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
