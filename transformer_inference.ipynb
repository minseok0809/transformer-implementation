{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tramsformer Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development Envrionment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"0\"\n",
    "\n",
    "import glob\n",
    "import torch\n",
    "import evaluate\n",
    "from model import TransformerForTranslation\n",
    "from prepare_data import SentencePieceTokenizer, TrainingDataset\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bleu Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "And at the end of that remarkable conversations with kids and their best friends all the United States , after two years , we ran together , studies data from another 10,000 children , put , to look up of what we thought were the most results of our research\n",
      "\n",
      "Label:\n",
      "And at the end of those remarkable conversations with kids and their best friends across the United States , after two years , we pulled together some survey data from another 10,000 children , drew up a set up of what we thought were the key findings of our research\n",
      "\n",
      "Bleu:\n",
      "0.5853669350898144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric = evaluate.load(\"bleu\")\n",
    "prediction = ['And', 'at', 'the', 'end', 'of', 'that', 'remarkable', 'conversations', 'with', 'kids', 'and', 'their', 'best', 'friends', 'all', 'the', 'United', 'States', ',', 'after', 'two', 'years', ',', 'we', 'ran', 'together', ',', 'studies', 'data', 'from', 'another', '10,000', 'children', ',', 'put', ',', 'to', 'look', 'up', 'of', 'what', 'we', 'thought', 'were', 'the', 'most', 'results', 'of', 'our', 'research']\n",
    "label = ['And', 'at', 'the', 'end', 'of', 'those', 'remarkable', 'conversations', 'with', 'kids', 'and', 'their', 'best', 'friends', 'across', 'the', 'United', 'States', ',', 'after', 'two', 'years', ',', 'we', 'pulled', 'together', 'some', 'survey', 'data', 'from', 'another', '10,000', 'children', ',', 'drew', 'up', 'a', 'set', 'up', 'of', 'what', 'we', 'thought', 'were', 'the', 'key', 'findings', 'of', 'our', 'research']\n",
    "prediction = ' '.join(prediction)\n",
    "label = ' '.join(label)\n",
    "result = metric.compute(predictions=[prediction], references=[[label]])\n",
    "sentence_bleu_score = result['bleu']\n",
    "print(\"Prediction:\\n{}\\n\".format(prediction))\n",
    "print(\"Label:\\n{}\\n\".format(label))\n",
    "print(\"Bleu:\\n{}\\n\".format(sentence_bleu_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "!python -m inference \\\n",
    "    --mode 'run' \\\n",
    "    --test_dataset 'F' \\\n",
    "    --inference_dataset 'inference/data/translation_pair' \\\n",
    "    --model_name 'demo_transformer_base' \\\n",
    "    --config './config/demo_transformer_base.json' \\\n",
    "    --load_model_path './custom_output/demo_transformer_base_51.pt' \\\n",
    "    --data_dir './data/iwslt17.de.en/' \\\n",
    "    --txt_dir 'txt/' \\\n",
    "    --tokenizer_dir 'data/iwslt17.de.en/tokenizer' \\\n",
    "    --tokenizer_model_name 'transformer-sp-bpe-iwslt' \\\n",
    "    --encoding_type 'bpe' \\\n",
    "    --src_lang 'de' \\\n",
    "    --tgt_lang 'en' \\\n",
    "    --max_seq_length 50 \\\n",
    "    --pad_id 0 \\\n",
    "    --unk_id 1 \\\n",
    "    --bos_id 2 \\\n",
    "    --eos_id 3 \\\n",
    "    --evaluation_metric 'bleu' \\\n",
    "    --seed 42 \\\n",
    "    --epoch 100 \\\n",
    "    --logging_step 100 \\\n",
    "    --gpu 0 \\\n",
    "    --batch_size 128 \\\n",
    "    --sinusoidal_wave 10000 \\\n",
    "    --embedding_dim 512 \\\n",
    "    --num_attention_heads 8 \\\n",
    "    --num_sub_layer 6 \\\n",
    "    --feed_forward_size 2048 \\\n",
    "    --attention_dropout_prob 0.1 \\\n",
    "    --label_smoothing 0.1 \\\n",
    "    --optimizer_coefficient 0.1 \\\n",
    "    --warmup_steps 4000 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --adam_beta1 0.9 \\\n",
    "    --adam_beta2 0.98 \\\n",
    "    --adam_epsilon 1e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SacreBLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "!python -m inference \\\n",
    "    --mode 'run' \\\n",
    "    --test_dataset 'F' \\\n",
    "    --inference_dataset 'inference/data/translation_pair' \\\n",
    "    --model_name 'demo_transformer_base' \\\n",
    "    --config './config/demo_transformer_base.json' \\\n",
    "    --load_model_path './custom_output/demo_transformer_base_51.pt' \\\n",
    "    --data_dir './data/iwslt17.de.en/' \\\n",
    "    --txt_dir 'txt/' \\\n",
    "    --tokenizer_dir 'data/iwslt17.de.en/tokenizer' \\\n",
    "    --tokenizer_model_name 'transformer-sp-bpe-iwslt' \\\n",
    "    --encoding_type 'bpe' \\\n",
    "    --src_lang 'de' \\\n",
    "    --tgt_lang 'en' \\\n",
    "    --max_seq_length 50 \\\n",
    "    --pad_id 0 \\\n",
    "    --unk_id 1 \\\n",
    "    --bos_id 2 \\\n",
    "    --eos_id 3 \\\n",
    "    --evaluation_metric 'sacrebleu' \\\n",
    "    --seed 42 \\\n",
    "    --epoch 100 \\\n",
    "    --logging_step 100 \\\n",
    "    --gpu 0 \\\n",
    "    --batch_size 128 \\\n",
    "    --sinusoidal_wave 10000 \\\n",
    "    --embedding_dim 512 \\\n",
    "    --num_attention_heads 8 \\\n",
    "    --num_sub_layer 6 \\\n",
    "    --feed_forward_size 2048 \\\n",
    "    --attention_dropout_prob 0.1 \\\n",
    "    --label_smoothing 0.1 \\\n",
    "    --optimizer_coefficient 0.1 \\\n",
    "    --warmup_steps 4000 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --adam_beta1 0.9 \\\n",
    "    --adam_beta2 0.98 \\\n",
    "    --adam_epsilon 1e-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Paper</b>\n",
    "<br>[Attention is all you need](https://arxiv.org/abs/1706.03762)\n",
    "\n",
    "<br><b>Data</b>\n",
    "<br>[IWSLT 2017-01](https://wit3.fbk.eu/2017-01)\n",
    "<br>[IWSLT 2017-01-B](https://wit3.fbk.eu/2017-01-b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
